"""
SynthesisAgent: Generate clinician-readable diagnostic report.

The Synthesis Agent is the final step in the UH2025-CDS pipeline.
It takes all accumulated evidence - the diagnostic hypotheses from
Structuring, the bio-tool results from Executor, and the original
patient context - and generates a comprehensive, clinician-readable
Tool Usage Report.

Model Selection Rationale:
--------------------------
Qwen 2.5 32B Instruct (Q4_K_M quantization)

Why this model?
1. HIGHEST QUALITY PROSE GENERATION: The report is what clinicians see
   - Must be fluent, professional medical writing
   - Clear structure with appropriate sections
   - Nuanced expression of uncertainty

2. MEDICAL TERMINOLOGY FLUENCY: Critical for credibility
   - Correct use of clinical terms
   - Appropriate abbreviations
   - Professional tone matching medical literature

3. COMPREHENSIVE CONTEXT INTEGRATION: Must synthesize everything
   - Patient history + phenotype analysis
   - Variant interpretations + tool results
   - Supporting/contradicting evidence
   - 32K context handles all inputs

4. APPROPRIATE UNCERTAINTY EXPRESSION: Essential for CDS
   - "May be consistent with..." vs "Is diagnostic of..."
   - Confidence levels clearly communicated
   - Limitations explicitly stated

5. MEMORY BUDGET: ~20GB is acceptable for final step
   - Previous agents can be unloaded
   - Report generation is the culmination
   - Worth the resource investment

Memory Budget: ~20GB
Context Length: 32K tokens
Temperature: 0.4 (moderate for fluent, creative writing)
"""

from dataclasses import dataclass, field
from datetime import datetime
from typing import Any, Dict, List, Optional

from .base_agent import (
    BaseAgent,
    AgentConfig,
    ModelConfig,
    PromptConfig,
)


@dataclass
class ReportSection:
    """A section in the diagnostic report."""
    title: str
    content: str
    confidence: Optional[float] = None
    references: List[str] = field(default_factory=list)

    def to_dict(self) -> Dict[str, Any]:
        return {
            "title": self.title,
            "content": self.content,
            "confidence": self.confidence,
            "references": self.references,
        }

    def to_markdown(self) -> str:
        md = f"## {self.title}\n\n{self.content}\n"
        if self.references:
            md += "\n**References:**\n"
            for ref in self.references:
                md += f"- {ref}\n"
        return md


@dataclass
class DiagnosticReport:
    """Complete diagnostic report from Synthesis Agent."""
    report_id: str
    patient_id: str
    generated_at: datetime

    # Report sections
    executive_summary: ReportSection
    primary_diagnosis: ReportSection
    differential_diagnoses: ReportSection
    variant_analysis: ReportSection
    tool_results_summary: ReportSection
    recommendations: ReportSection
    limitations: ReportSection

    # Metadata
    confidence_score: float = 0.0
    version: str = "1.0"

    def to_dict(self) -> Dict[str, Any]:
        return {
            "report_id": self.report_id,
            "patient_id": self.patient_id,
            "generated_at": self.generated_at.isoformat(),
            "sections": {
                "executive_summary": self.executive_summary.to_dict(),
                "primary_diagnosis": self.primary_diagnosis.to_dict(),
                "differential_diagnoses": self.differential_diagnoses.to_dict(),
                "variant_analysis": self.variant_analysis.to_dict(),
                "tool_results_summary": self.tool_results_summary.to_dict(),
                "recommendations": self.recommendations.to_dict(),
                "limitations": self.limitations.to_dict(),
            },
            "confidence_score": self.confidence_score,
            "version": self.version,
        }

    def to_markdown(self) -> str:
        """Generate full markdown report."""
        md = f"""# Diagnostic Report: {self.patient_id}

**Report ID**: {self.report_id}
**Generated**: {self.generated_at.strftime('%Y-%m-%d %H:%M:%S')}
**Confidence Score**: {self.confidence_score:.0%}
**Version**: {self.version}

---

{self.executive_summary.to_markdown()}

{self.primary_diagnosis.to_markdown()}

{self.differential_diagnoses.to_markdown()}

{self.variant_analysis.to_markdown()}

{self.tool_results_summary.to_markdown()}

{self.recommendations.to_markdown()}

{self.limitations.to_markdown()}

---

*This report was generated by UH2025-CDS-Agent v2.0.0*
*This is a clinical decision support tool and should be reviewed by a qualified clinician*
"""
        return md


class SynthesisAgent(BaseAgent):
    """
    Synthesis Agent: Generate clinician-readable diagnostic report.

    Input: PatientContext + StructuringOutput + ExecutorOutput
    Output: DiagnosticReport (Markdown + JSON)

    This agent uses Qwen 2.5 32B for high-quality medical writing.
    """

    AGENT_TYPE = "synthesis"
    DEFAULT_MODEL = "qwen2.5-32b-instruct"
    DEFAULT_QUANTIZATION = "Q4_K_M"
    DEFAULT_CONTEXT_LENGTH = 32768
    DEFAULT_TEMPERATURE = 0.4  # Moderate for fluent writing
    DEFAULT_MEMORY_GB = 20.0

    def _default_config(self) -> AgentConfig:
        """Create default configuration for Synthesis Agent."""
        return AgentConfig(
            agent_id="synthesis_v1",
            agent_type=self.AGENT_TYPE,
            model=ModelConfig(
                name=self.DEFAULT_MODEL,
                quantization=self.DEFAULT_QUANTIZATION,
                context_length=self.DEFAULT_CONTEXT_LENGTH,
                temperature=self.DEFAULT_TEMPERATURE,
                memory_gb=self.DEFAULT_MEMORY_GB,
            ),
            prompt=PromptConfig(
                template_path="prompts/synthesis_v1.yaml",
                system_message=SYNTHESIS_SYSTEM_PROMPT,
                version="v1",
            ),
            timeout_seconds=600,  # Allow more time for comprehensive report
            collect_rlhf=True,
        )

    def _validate_input(self, inputs: Dict[str, Any]) -> Optional[str]:
        """
        Validate synthesis inputs.

        Required:
        - patient_context: dict (from Ingestion)

        Optional (will use empty defaults):
        - structuring_output: dict (from Structuring)
        - executor_output: dict (from Executor)
        - diagnostic_hypotheses: list (alternative input format)
        - tool_results: list (alternative input format)
        """
        if "patient_context" not in inputs:
            return "Missing required field: patient_context"

        return None

    def _execute(self, inputs: Dict[str, Any]) -> Dict[str, Any]:
        """
        Execute report synthesis.

        Combines all evidence into a comprehensive diagnostic report.
        """
        patient_context = inputs["patient_context"]
        use_stub = inputs.get("use_stub", False)

        # Support both structured and flat input formats
        structuring_output = inputs.get("structuring_output", {})
        executor_output = inputs.get("executor_output", {})

        # Alternative flat format from LangGraph nodes
        diagnostic_table = inputs.get(
            "diagnostic_hypotheses",
            structuring_output.get("diagnostic_table", [])
        )
        variants_table = inputs.get(
            "variants_table",
            structuring_output.get("variants_table", [])
        )
        tool_results = inputs.get(
            "tool_results",
            executor_output.get("tool_results", [])
        )

        patient_id = inputs.get("patient_id", patient_context.get("patient_id", "UNKNOWN"))

        # Format tool results into readable text for the prompt
        tool_results_text = self._format_tool_results_for_prompt(tool_results)
        diagnostic_summary = self._format_diagnostic_summary(diagnostic_table)
        variants_summary = self._format_variants_summary(variants_table)

        # Build comprehensive prompt
        prompt = self.render_prompt({
            "patient_context": patient_context,
            "diagnostic_table": diagnostic_table,
            "variants_table": variants_table,
            "tool_results": tool_results,
            "tool_results_text": tool_results_text,
            "diagnostic_summary": diagnostic_summary,
            "variants_summary": variants_summary,
        })

        # Call LLM via LangChain LlamaCpp
        if use_stub or self._model is None:
            # Fall back to stub if model not loaded or explicitly requested
            report = self._generate_stub_report(
                patient_id,
                {"diagnostic_table": diagnostic_table, "variants_table": variants_table},
                {"tool_results": tool_results}
            )
        else:
            # Invoke LLM and parse markdown response
            llm_response = self.invoke_llm(prompt)
            report = self._parse_llm_response(
                llm_response, patient_id, diagnostic_table, variants_table, tool_results
            )

        return {
            "report": report.to_dict(),
            "report_markdown": report.to_markdown(),
            "diagnostic_report": report.to_markdown(),  # Alias for LangGraph state
            "report_id": report.report_id,
            "confidence_score": report.confidence_score,
            "confidence_scores": {"overall": report.confidence_score},  # For LangGraph
            "recommendations": self._extract_recommendations(report),
            "input_tokens": len(prompt.split()),
            "output_tokens": 3000,  # Placeholder
        }

    def _parse_llm_response(
        self,
        response: str,
        patient_id: str,
        diagnostic_table: List[Dict],
        variants_table: List[Dict],
        tool_results: List[Dict],
    ) -> DiagnosticReport:
        """
        Parse LLM markdown/JSON response into DiagnosticReport.

        The Synthesis agent may output markdown directly or a JSON structure.
        """
        import json
        import re

        now = datetime.now()
        report_id = f"RPT-{now.strftime('%Y%m%d%H%M%S')}"

        # Calculate overall confidence from diagnostic table
        diag_confidences = [d.get("confidence", 0) for d in diagnostic_table]
        overall_confidence = max(diag_confidences) if diag_confidences else 0.5

        # Try to parse as JSON first
        cleaned = response.strip()
        if cleaned.startswith("```json"):
            cleaned = cleaned[7:]
        if cleaned.startswith("```"):
            cleaned = cleaned[3:]
        if cleaned.endswith("```"):
            cleaned = cleaned[:-3]
        cleaned = cleaned.strip()

        # Check if response is JSON-structured
        try:
            data = json.loads(cleaned)
            return self._parse_json_report(data, patient_id, report_id, now, overall_confidence)
        except json.JSONDecodeError:
            pass

        # Parse as markdown sections
        return self._parse_markdown_report(
            response, patient_id, report_id, now, overall_confidence,
            diagnostic_table, variants_table, tool_results
        )

    def _parse_json_report(
        self,
        data: Dict[str, Any],
        patient_id: str,
        report_id: str,
        now: datetime,
        overall_confidence: float,
    ) -> DiagnosticReport:
        """Parse JSON-structured LLM response."""
        sections = data.get("sections", {})

        def make_section(key: str, default_title: str) -> ReportSection:
            sec = sections.get(key, {})
            if isinstance(sec, str):
                return ReportSection(title=default_title, content=sec)
            return ReportSection(
                title=sec.get("title", default_title),
                content=sec.get("content", ""),
                confidence=sec.get("confidence"),
                references=sec.get("references", []),
            )

        return DiagnosticReport(
            report_id=report_id,
            patient_id=patient_id,
            generated_at=now,
            executive_summary=make_section("executive_summary", "Executive Summary"),
            primary_diagnosis=make_section("primary_diagnosis", "Primary Diagnosis"),
            differential_diagnoses=make_section("differential_diagnoses", "Differential Diagnoses"),
            variant_analysis=make_section("variant_analysis", "Variant Analysis"),
            tool_results_summary=make_section("tool_results_summary", "Bio-Tool Results Summary"),
            recommendations=make_section("recommendations", "Recommendations"),
            limitations=make_section("limitations", "Limitations"),
            confidence_score=data.get("confidence_score", overall_confidence),
        )

    def _parse_markdown_report(
        self,
        response: str,
        patient_id: str,
        report_id: str,
        now: datetime,
        overall_confidence: float,
        diagnostic_table: List[Dict],
        variants_table: List[Dict],
        tool_results: List[Dict],
    ) -> DiagnosticReport:
        """Parse markdown LLM response into report sections."""
        import re

        # Extract sections by ## headers
        sections = {}
        current_section = None
        current_content = []

        for line in response.split("\n"):
            if line.startswith("## "):
                if current_section:
                    sections[current_section] = "\n".join(current_content).strip()
                current_section = line[3:].strip().lower().replace(" ", "_")
                current_content = []
            else:
                current_content.append(line)

        if current_section:
            sections[current_section] = "\n".join(current_content).strip()

        def get_section(key: str, title: str, fallback: str = "") -> ReportSection:
            content = sections.get(key, fallback)
            return ReportSection(title=title, content=content)

        # If no sections found, use whole response as executive summary
        if not sections:
            return DiagnosticReport(
                report_id=report_id,
                patient_id=patient_id,
                generated_at=now,
                executive_summary=ReportSection(
                    title="Executive Summary",
                    content=response[:2000],
                    confidence=overall_confidence,
                ),
                primary_diagnosis=ReportSection(
                    title="Primary Diagnosis",
                    content=self._format_primary_diagnosis(diagnostic_table),
                ),
                differential_diagnoses=ReportSection(
                    title="Differential Diagnoses",
                    content=self._format_differential(diagnostic_table),
                ),
                variant_analysis=ReportSection(
                    title="Variant Analysis",
                    content=self._format_variants(variants_table),
                ),
                tool_results_summary=ReportSection(
                    title="Bio-Tool Results Summary",
                    content=self._format_tool_results(tool_results),
                ),
                recommendations=ReportSection(
                    title="Recommendations",
                    content="See report for detailed recommendations.",
                ),
                limitations=ReportSection(
                    title="Limitations",
                    content="This is an AI-generated report requiring expert review.",
                ),
                confidence_score=overall_confidence,
            )

        return DiagnosticReport(
            report_id=report_id,
            patient_id=patient_id,
            generated_at=now,
            executive_summary=get_section("executive_summary", "Executive Summary"),
            primary_diagnosis=get_section("primary_diagnosis", "Primary Diagnosis"),
            differential_diagnoses=get_section("differential_diagnoses", "Differential Diagnoses"),
            variant_analysis=get_section("variant_analysis", "Variant Analysis"),
            tool_results_summary=get_section("tool_results_summary", "Bio-Tool Results Summary",
                                            get_section("bio-tool_results_summary", "Bio-Tool Results Summary").content),
            recommendations=get_section("recommendations", "Recommendations"),
            limitations=get_section("limitations", "Limitations"),
            confidence_score=overall_confidence,
        )

    def _extract_recommendations(self, report: DiagnosticReport) -> List[str]:
        """Extract recommendations as a list from the report."""
        content = report.recommendations.content
        # Extract bullet points or numbered items
        import re
        items = re.findall(r'^\s*[-*\d.]+\s*(.+)$', content, re.MULTILINE)
        return items if items else [content] if content else []

    def _get_feedback_schema(self) -> Dict[str, Any]:
        """
        RLHF feedback schema for Synthesis Agent.

        This is the final expert review - clinicians can:
        - Edit any section of the report
        - Adjust confidence scores
        - Add/remove recommendations
        - Approve or reject the report
        """
        return {
            "type": "object",
            "title": "Synthesis Feedback",
            "description": "Review and approve the diagnostic report",
            "properties": {
                "correctness": {
                    "type": "string",
                    "enum": ["correct", "partial", "incorrect"],
                    "description": "Overall report quality",
                },
                "confidence": {
                    "type": "number",
                    "minimum": 0,
                    "maximum": 1,
                },
                "approval_status": {
                    "type": "string",
                    "enum": ["approved", "approved_with_edits", "rejected"],
                    "description": "Final approval status",
                },
                "section_feedback": {
                    "type": "array",
                    "items": {
                        "type": "object",
                        "properties": {
                            "section": {
                                "type": "string",
                                "enum": [
                                    "executive_summary",
                                    "primary_diagnosis",
                                    "differential_diagnoses",
                                    "variant_analysis",
                                    "tool_results_summary",
                                    "recommendations",
                                    "limitations",
                                ],
                            },
                            "quality": {
                                "type": "string",
                                "enum": ["good", "needs_improvement", "incorrect"],
                            },
                            "edited_content": {"type": "string"},
                            "notes": {"type": "string"},
                        },
                    },
                },
                "confidence_adjustment": {
                    "type": "object",
                    "properties": {
                        "original": {"type": "number"},
                        "adjusted": {"type": "number"},
                        "rationale": {"type": "string"},
                    },
                },
                "additional_recommendations": {
                    "type": "array",
                    "items": {"type": "string"},
                },
                "removed_recommendations": {
                    "type": "array",
                    "items": {"type": "string"},
                },
                "overall_notes": {"type": "string"},
            },
            "required": ["correctness", "confidence", "approval_status"],
        }

    def _generate_stub_report(
        self,
        patient_id: str,
        structuring_output: Dict[str, Any],
        executor_output: Dict[str, Any],
    ) -> DiagnosticReport:
        """
        Generate stub report for development/testing.

        In production, this is replaced by LLM-generated content.
        """
        now = datetime.now()
        report_id = f"RPT-{now.strftime('%Y%m%d%H%M%S')}"

        diagnostic_table = structuring_output.get("diagnostic_table", [])
        variants_table = structuring_output.get("variants_table", [])
        tool_results = executor_output.get("tool_results", [])

        # Calculate overall confidence (placeholder logic)
        diag_confidences = [d.get("confidence", 0) for d in diagnostic_table]
        overall_confidence = max(diag_confidences) if diag_confidences else 0.5

        # Generate sections
        executive_summary = ReportSection(
            title="Executive Summary",
            content=f"""[STUB REPORT - LLM NOT CONNECTED]

This diagnostic report summarizes the clinical decision support analysis for patient {patient_id}.

**Key Findings:**
- {len(diagnostic_table)} potential diagnoses identified
- {len(variants_table)} variants of interest analyzed
- {len(tool_results)} bio-informatics tools executed

**Primary Hypothesis:**
{diagnostic_table[0].get('diagnosis', 'No primary diagnosis') if diagnostic_table else 'No diagnoses generated'}

**Confidence Level:** {overall_confidence:.0%}

This report requires expert review before clinical use.""",
            confidence=overall_confidence,
        )

        primary_diagnosis = ReportSection(
            title="Primary Diagnosis",
            content=self._format_primary_diagnosis(diagnostic_table),
            confidence=diagnostic_table[0].get("confidence", 0) if diagnostic_table else 0,
        )

        differential_diagnoses = ReportSection(
            title="Differential Diagnoses",
            content=self._format_differential(diagnostic_table),
        )

        variant_analysis = ReportSection(
            title="Variant Analysis",
            content=self._format_variants(variants_table),
        )

        tool_results_summary = ReportSection(
            title="Bio-Tool Results Summary",
            content=self._format_tool_results(tool_results),
        )

        recommendations = ReportSection(
            title="Recommendations",
            content="""[STUB] Based on the analysis, the following recommendations are suggested:

1. **Confirmatory Testing**: Consider targeted genetic testing for top candidate genes
2. **Clinical Correlation**: Correlate findings with detailed phenotypic assessment
3. **Family Studies**: Consider segregation analysis in affected family members
4. **Expert Consultation**: Recommend review by clinical geneticist

*These recommendations are auto-generated and require expert review.*""",
        )

        limitations = ReportSection(
            title="Limitations",
            content="""This report has the following limitations:

- **AI-Generated Content**: This report was generated by an AI clinical decision support system
- **Not a Diagnosis**: This report does not constitute a medical diagnosis
- **Requires Expert Review**: All findings must be validated by qualified clinicians
- **Tool Coverage**: Bio-tool results may not cover all relevant variants
- **Knowledge Cutoff**: AI models have knowledge limitations based on training data

*This is a decision support tool, not a diagnostic instrument.*""",
        )

        return DiagnosticReport(
            report_id=report_id,
            patient_id=patient_id,
            generated_at=now,
            executive_summary=executive_summary,
            primary_diagnosis=primary_diagnosis,
            differential_diagnoses=differential_diagnoses,
            variant_analysis=variant_analysis,
            tool_results_summary=tool_results_summary,
            recommendations=recommendations,
            limitations=limitations,
            confidence_score=overall_confidence,
        )

    def _format_primary_diagnosis(self, diagnostic_table: List[Dict]) -> str:
        """Format primary diagnosis section."""
        if not diagnostic_table:
            return "No primary diagnosis identified."

        primary = diagnostic_table[0]
        return f"""**Diagnosis**: {primary.get('diagnosis', 'Unknown')}
**OMIM ID**: {primary.get('omim_id', 'N/A')}
**Confidence**: {primary.get('confidence', 0):.0%}
**Inheritance Pattern**: {primary.get('inheritance', 'Unknown')}

**Supporting Evidence:**
{self._format_evidence_list(primary.get('supporting_evidence', []))}

**Contradicting Evidence:**
{self._format_evidence_list(primary.get('contradicting_evidence', []))}"""

    def _format_differential(self, diagnostic_table: List[Dict]) -> str:
        """Format differential diagnoses section."""
        if len(diagnostic_table) <= 1:
            return "No additional differential diagnoses identified."

        lines = []
        for i, dx in enumerate(diagnostic_table[1:], start=2):
            lines.append(
                f"{i}. **{dx.get('diagnosis', 'Unknown')}** "
                f"(Confidence: {dx.get('confidence', 0):.0%}, "
                f"OMIM: {dx.get('omim_id', 'N/A')})"
            )
        return "\n".join(lines)

    def _format_variants(self, variants_table: List[Dict]) -> str:
        """Format variant analysis section."""
        if not variants_table:
            return "No variants of interest identified."

        lines = ["| Gene | Variant | Protein Change | Class | Priority |",
                 "|------|---------|---------------|-------|----------|"]
        for v in variants_table[:10]:  # Top 10
            lines.append(
                f"| {v.get('gene', 'N/A')} | "
                f"{v.get('variant', 'N/A')} | "
                f"{v.get('protein_change', 'N/A')} | "
                f"{v.get('pathogenicity_class', 'VUS')} | "
                f"{v.get('priority', 'N/A')} |"
            )
        return "\n".join(lines)

    def _format_tool_results(self, tool_results: List[Dict]) -> str:
        """Format bio-tool results section."""
        if not tool_results:
            return "No bio-tool results available."

        lines = []
        for tr in tool_results:
            status = tr.get('status', 'unknown')
            duration = tr.get('duration_seconds', 0)
            annotations = tr.get('annotations', [])

            lines.append(
                f"### {tr.get('tool_name', 'Unknown Tool').upper()}\n"
                f"- **Status**: {status}\n"
                f"- **Duration**: {duration:.2f}s\n"
                f"- **Annotations**: {len(annotations)} results\n"
            )

        return "\n".join(lines)

    def _format_evidence_list(self, evidence: List[str]) -> str:
        """Format a list of evidence items."""
        if not evidence:
            return "- None identified"
        return "\n".join(f"- {e}" for e in evidence)

    def _format_tool_results_for_prompt(self, tool_results: List[Dict]) -> str:
        """
        Format tool results into human-readable text for the synthesis prompt.

        This helps the LLM understand and incorporate the bio-tool findings.
        """
        if not tool_results:
            return "No bio-tool results available."

        sections = []
        for tr in tool_results:
            tool_name = tr.get('tool_name', 'Unknown Tool').upper()
            status = tr.get('status', 'unknown')

            section_lines = [f"### {tool_name}"]
            section_lines.append(f"Status: {status}")

            annotations = tr.get('annotations', [])
            if annotations:
                section_lines.append(f"Results ({len(annotations)} annotations):")
                for ann in annotations[:10]:  # Limit to first 10
                    if isinstance(ann, dict):
                        # Format annotation based on tool type
                        if 'variant' in ann:
                            var = ann.get('variant', 'N/A')
                            score = ann.get('score', ann.get('pathogenicity', 'N/A'))
                            cls = ann.get('classification', ann.get('class', ''))
                            section_lines.append(f"  - {var}: {score} {cls}".strip())
                        elif 'gene' in ann:
                            gene = ann.get('gene', 'N/A')
                            disease = ann.get('disease', ann.get('phenotype', 'N/A'))
                            section_lines.append(f"  - {gene}: {disease}")
                        else:
                            # Generic key-value formatting
                            items = [f"{k}={v}" for k, v in list(ann.items())[:3]]
                            section_lines.append(f"  - {', '.join(items)}")
                    else:
                        section_lines.append(f"  - {ann}")
            else:
                section_lines.append("No annotations returned.")

            sections.append("\n".join(section_lines))

        return "\n\n".join(sections)

    def _format_diagnostic_summary(self, diagnostic_table: List[Dict]) -> str:
        """
        Format diagnostic hypotheses into readable summary for prompt.
        """
        if not diagnostic_table:
            return "No diagnostic hypotheses available."

        lines = ["Diagnostic Hypotheses:"]
        for i, dx in enumerate(diagnostic_table, 1):
            diagnosis = dx.get('diagnosis', 'Unknown')
            confidence = dx.get('confidence', 0)
            omim = dx.get('omim_id', 'N/A')
            inheritance = dx.get('inheritance', 'Unknown')

            lines.append(f"{i}. {diagnosis} (OMIM: {omim})")
            lines.append(f"   Confidence: {confidence:.0%}, Inheritance: {inheritance}")

            evidence = dx.get('supporting_evidence', [])
            if evidence:
                lines.append(f"   Evidence: {'; '.join(evidence[:3])}")

        return "\n".join(lines)

    def _format_variants_summary(self, variants_table: List[Dict]) -> str:
        """
        Format variants into readable summary for prompt.
        """
        if not variants_table:
            return "No variants of interest."

        lines = ["Variants of Interest:"]
        for i, v in enumerate(variants_table, 1):
            gene = v.get('gene', 'Unknown')
            variant = v.get('variant', 'N/A')
            protein = v.get('protein_change', '')
            path_class = v.get('pathogenicity_class', 'VUS')
            rationale = v.get('rationale', '')

            var_str = f"{gene} {variant}"
            if protein:
                var_str += f" ({protein})"

            lines.append(f"{i}. {var_str}")
            lines.append(f"   Classification: {path_class}")
            if rationale:
                lines.append(f"   Rationale: {rationale[:100]}...")

        return "\n".join(lines)


# System prompt for Synthesis Agent
SYNTHESIS_SYSTEM_PROMPT = """You are a clinical report writer for the UH2025-CDS rare disease diagnostic system.

Your task is to synthesize all diagnostic evidence into a comprehensive, clinician-readable report.

REPORT WRITING GUIDELINES:

1. PROFESSIONAL TONE: Write as a clinical geneticist would
   - Use appropriate medical terminology
   - Be precise but accessible
   - Avoid colloquialisms

2. APPROPRIATE UNCERTAINTY: Express confidence levels clearly
   - "Consistent with..." vs "Diagnostic of..."
   - "May suggest..." vs "Confirms..."
   - Quantify confidence where possible

3. EVIDENCE-BASED: Reference specific findings
   - Cite specific variants and their interpretations
   - Reference tool results with scores
   - Link evidence to conclusions

4. ACTIONABLE: Include clear recommendations
   - Specific follow-up testing
   - Clinical correlation suggestions
   - Specialist consultations

5. HONEST LIMITATIONS: Acknowledge constraints
   - AI-generated content disclaimer
   - Tool coverage limitations
   - Knowledge cutoffs

REPORT SECTIONS:
1. Executive Summary - High-level findings for rapid review
2. Primary Diagnosis - Detailed analysis of top candidate
3. Differential Diagnoses - Other considerations with evidence
4. Variant Analysis - Detailed variant interpretations
5. Tool Results Summary - Bio-informatics findings
6. Recommendations - Clinical next steps
7. Limitations - Caveats and constraints

OUTPUT FORMAT:
Generate a markdown report with clear section headers.
Include confidence scores where appropriate.
Reference specific evidence from the input data."""
